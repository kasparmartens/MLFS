
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\boldU}{\mathbf{U}}
\newcommand{\boldW}{\mathbf{W}}
\newcommand{\boldV}{\mathbf{V}}
\newcommand{\boldX}{\mathbf{X}}
\newcommand{\boldbeta}{\boldsymbol{\beta}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

# MLFS method

Suppose we have $N$ data points, each having a label $y_i \in \{1, ..., C\}$ and information from various views $\boldX^{(m)}, m \in \{1, ..., M\}$. 

For each view $m$, there are view-specific latent matrices $\boldU^{(m)} \in \R^{N \times d_m}$ which are generated by a *shared* latent representation $\boldV \in \R^{N \times R}$ and view-specific sparse weight matrices $\boldW^{(m)} \in \R^{R \times d_m}$. Each row $\boldU_i^{(m)}$ is generated as follows

\[
\boldU_i^{(m)} \sim \N(\boldV_i \boldW^{(m)}, \frac{1}{\gamma_m} I)
\]

Our data $\boldX_{ij}^{(m)}$ is then generated

- for gaussian views, $\boldX_{ij}^{(m)} = \boldU_{ij}^{(m)}$
- for ordinal views, $\boldX_{ij}^{(m)} = l$ if and only if $g_{l-1}^m < \boldU_{ij}^{(m)} < g_l^m$ for some cutpoints $g_0^m < ... < g_{L_m}^m$

And the labels $y_i$ are generated $y_i = \argmax_c{z_{ic}}$, where $z_{ic} \sim \N(\boldV_i \boldbeta_c, 1)$ for classes $c$ and $\boldbeta_c \in \R^R$. 


# Testing MLFS method on simulated data

Generate two views, both with 10 features. Altogether 200 data points (100 for training, 100 for testing), number of classes $C=2$. 

- Two Gaussian views
- One gaussian, one ordinal (with 3 levels)
- Both ordinal views (both with 3 levels)

Performance ("prediction accuracy") reported as the proportion of correct classifications. 



### Sanity check

Perfect scenario (data generated exactly according to the model). 

![](experiment1_files/figure-html/unnamed-chunk-2-1.png)



### Can the model handle large number of irrelevant features?

Each view has (10 + irrelevant) features now

![](experiment1_files/figure-html/unnamed-chunk-3-1.png)

### What if the dimensionality of latent space is misspecified?

In the generated data, the underlying latent space was 6-dimensional. When fitting the model, lets consider misspecified values $\{2, 4 < 6 < 10, 20\}$. 

![](experiment1_files/figure-html/unnamed-chunk-4-1.png)
