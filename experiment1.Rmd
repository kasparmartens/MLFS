---
output: 
  html_document:
    keep_md: true
---

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\boldU}{\mathbf{U}}
\newcommand{\boldW}{\mathbf{W}}
\newcommand{\boldV}{\mathbf{V}}
\newcommand{\boldX}{\mathbf{X}}
\newcommand{\boldbeta}{\boldsymbol{\beta}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

# MLFS method

Suppose we have $N$ data points, each having a label $y_i \in \{1, ..., C\}$ and information from various views $\boldX^{(m)}, m \in \{1, ..., M\}$. 

For each view $m$, there are view-specific latent matrices $\boldU^{(m)} \in \R^{N \times d_m}$ which are generated by a *shared* latent representation $\boldV \in \R^{N \times R}$ and view-specific sparse weight matrices $\boldW^{(m)} \in \R^{R \times d_m}$. Each row $\boldU_i^{(m)}$ is generated as follows

\[
\boldU_i^{(m)} \sim \N(\boldV_i \boldW^{(m)}, \frac{1}{\gamma_m} I)
\]

Our data $\boldX_{ij}^{(m)}$ is then generated

- for gaussian views, $\boldX_{ij}^{(m)} = \boldU_{ij}^{(m)}$
- for ordinal views, $\boldX_{ij}^{(m)} = l$ if and only if $g_{l-1}^m < \boldU_{ij}^{(m)} < g_l^m$ for some cutpoints $g_0^m < ... < g_{L_m}^m$

And the labels $y_i$ are generated $y_i = \argmax_c{z_{ic}}$, where $z_{ic} \sim \N(\boldV_i \boldbeta_c, 1)$ for classes $c$ and $\boldbeta_c \in \R^R$. 


# Testing MLFS method on simulated data

Generate two views, both with 10 features. Altogether 200 data points (100 for training, 100 for testing), number of classes $C=2$. 

- Two Gaussian views
- One gaussian, one ordinal (with 3 levels)
- Both ordinal views (both with 3 levels)

Performance ("prediction accuracy") reported as the proportion of correct classifications. 

```{r, echo=FALSE, message=FALSE}
source("experiment.R")

H = rbind(c(1, 1), 
          c(1, 1), 
          c(1, 0), 
          c(1, 0), 
          c(0, 1), 
          c(0, 1))

set.seed(0)
R = nrow(H)
d = c(10, 10)

```

### Sanity check

Perfect scenario (data generated exactly according to the model). 

```{r, echo=FALSE}
# type = c("gaussian", "gaussian")
# res1 = experiment0(H, d, type, n_rep = 5)
# type = c("gaussian", "ordinal")
# res2 = experiment0(H, d, type, n_rep = 5)
# type = c("ordinal", "ordinal")
# res3 = experiment0(H, d, type, n_rep = 5)
# res = data.frame(rbind(res1, res2, res3), type = rep(c("gaussian + gaussian", "gaussian + ordinal", "ordinal + ordinal"), each=nrow(res1)))
load("temp_res0.RData")
df.m = res %>%
  melt(measure.vars = c("train", "test")) 

ggplot(df.m, aes(variable, value, col=variable)) + 
  geom_boxplot() + facet_wrap(~ type) + 
  theme_bw() + ylim(0, 1) + 
  ylab("Prediction accuracy") + xlab("") + 
  scale_color_brewer(palette="Set1")

```



### Can the model handle large number of irrelevant features?

Each view has (10 + irrelevant) features now

```{r, echo=FALSE}
# n_irrelevant_features = c(0, 10, 100, 1000, 10000)
# type = c("gaussian", "gaussian")
# res1 = experiment1(n_irrelevant_features, H, d, type, n_rep = 5)
# type = c("gaussian", "ordinal")
# res2 = experiment1(n_irrelevant_features, H, d, type, n_rep = 5)
# type = c("ordinal", "ordinal")
# res3 = experiment1(n_irrelevant_features, H, d, type, n_rep = 5)
# res = data.frame(rbind(res1, res2, res3), type = rep(c("gaussian + gaussian", "gaussian + ordinal", "ordinal + ordinal"), each=nrow(res1)))
# save(res, file="temp_res1.RData")
load("temp_res1.RData")
df.m = res %>%
  melt(measure.vars = c("train", "test")) 

ggplot(df.m, aes(factor(n_irrelevant_features), value, col=variable)) + 
  geom_boxplot() + facet_wrap(~ type) + 
  theme_bw() + ylim(0, 1) + 
  xlab("Number of irrelevant features") + ylab("Prediction accuracy") + 
  scale_color_brewer(palette="Set1")
```

### What if the dimensionality of latent space is misspecified?

In the generated data, the underlying latent space was 6-dimensional. When fitting the model, lets consider misspecified values $\{2, 4 < 6 < 10, 20\}$. 

```{r, echo=FALSE}
# R_values = c(2, 4, 10, 20)
# type = c("gaussian", "gaussian")
# res1 = experiment2(R_values, H, d, type, n_rep = 5)
# type = c("gaussian", "ordinal")
# res2 = experiment2(R_values, H, d, type, n_rep = 5)
# type = c("ordinal", "ordinal")
# res3 = experiment2(R_values, H, d, type, n_rep = 5)
# res = data.frame(rbind(res1, res2, res3), type = rep(c("gaussian + gaussian", "gaussian + ordinal", "ordinal + ordinal"), each=nrow(res1)))
# save(res, file="temp_res2.RData")
load("temp_res2.RData")
df.m = res %>%
  melt(measure.vars = c("train", "test")) 

ggplot(df.m, aes(factor(latent_dim), value, col=variable)) + 
  geom_boxplot() + facet_wrap(~ type) + 
  theme_bw() + ylim(0, 1) + 
  xlab("Latent space dimensionality") + ylab("Prediction accuracy") + 
  scale_color_brewer(palette="Set1")

```
